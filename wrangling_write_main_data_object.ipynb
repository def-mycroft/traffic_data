{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle_funcs as pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm getting this data from the [NHTSA](https://www-fars.nhtsa.dot.gov/QueryTool/QuerySection/SelectYear.aspx)\n",
    "\n",
    "I could just do a massive data dump, but I'm not sure this makes sense. It seems better to build on columns as needed. \n",
    "\n",
    "Apparently it isn't possible to do multiyear queries? This makes time series annoying but that isn't too bad (are time series really central to this sort of analysis?)\n",
    "\n",
    "I realized that the case numbers are not unique, which means that it would be hard to append in new columns. May be able to match the case number, state number, and some other identifier if needing to append a new column, but I don't think I'm going to do this at the moment. \n",
    "\n",
    "Process for pulling more data:\n",
    "\n",
    "* Select a year from the dropdown in the above link\n",
    "* Option 1 in the second screen probably makes the most sense \n",
    "* Select crashes fields (I'm not looking at others at the moment). \n",
    "* Select \"Case Listing\"\n",
    "* Deselect \"State\" and make sure that only Case Number is selected.\n",
    "* Select output stats\n",
    "* Name the export\n",
    "* Preview data\n",
    "* Export via txt (gets a tab seperated value)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to create a main table and add columns to this as I continue analyzing. \n",
    "\n",
    "Creating the main table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_table('crashes_date_time.txt', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del data['Unnamed: 4'] # there are tabs at the end of these files, just have to delete a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>casenum</th>\n",
       "      <th>accdate</th>\n",
       "      <th>acctime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>952</td>\n",
       "      <td>6022015</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>8142015</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>546</td>\n",
       "      <td>8222015</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>164</td>\n",
       "      <td>10142015</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>238</td>\n",
       "      <td>5022015</td>\n",
       "      <td>1246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      casenum   accdate  acctime\n",
       "Obs.                            \n",
       "1         952   6022015     1700\n",
       "2         150   8142015      609\n",
       "3         546   8222015      905\n",
       "4         164  10142015      100\n",
       "5         238   5022015     1246"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Object to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write this to a pickle file, creating the main data file. \n",
    "# Can't test to see if the dataframes are exactly the same because of issues with Pandas\n",
    "\n",
    "pk.pickle_object(data, 'data', test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the pickled dataframe to test\n",
    "new_data = pk.unpickle_object('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector operation on dataframes, return array with True in cell if don't match\n",
    "test = new_data.values != data.values\n",
    "test.sum()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
